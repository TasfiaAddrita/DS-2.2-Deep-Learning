{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "\n",
    "Build and train a MLP Model to classify MNIST dataset\n",
    "\n",
    "1. MLP Network accepts 1D data. So we should flatten our 2D image, then print the dimension of the result arrays.\n",
    "2. Normalize data by rescaling them to (0,1)\n",
    "3. Convert label arrays to 1-hot representation (`keras.utils.to_categorical`)\n",
    "4. Define Model\n",
    "    - Hidden Layer 1: Fully Connected + Relu Activition (e.g. 512 Neurons)\n",
    "    - Hidden Layer 2: Fully Connected + Relu Activition (e.g. 512 Neurons)\n",
    "    - Outout Layer: Fully Connected + Softmax Activition\n",
    "      \n",
    "      \n",
    "5. Build and train a CNN+MLP deep learning model with Keras with followings specs for MNIST dataset:\n",
    "  \n",
    "   ``` \n",
    "       Conv2D(32, kernel_size=(3, 3), activation='relu')\n",
    "       Conv2D(64, kernel_size=(3, 3), activation='relu')\n",
    "       MaxPooling2D(pool_size=(2, 2))\n",
    "       Dense(128, activation='relu')\n",
    "       Dense(num_classes, activation='softmax')\n",
    "   ```\n",
    "     \n",
    "     \n",
    "6. Also build another model with BatchNormalization and Dropout. Compare these two CNN + MLP models performance for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import matplotlib.pyplot as plt # This package is for plotting\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Conv2D, MaxPooling2D, Dropout, Flatten, BatchNormalization, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import warnings\n",
    "%matplotlib inline  \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize x data to (0, 1)\n",
    "X_train = X_train/np.max(X_train)\n",
    "X_test = X_test/np.max(X_test)\n",
    "\n",
    "# normalize y data to one-hot\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect accuracy data of each model\n",
    "acc = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP NN only accepts 1D data, should flatten 2D image\n",
    "X_train = np.reshape(X_train, [-1, 28**2])\n",
    "X_test = np.reshape(X_test, [-1, 28**2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = Sequential()\n",
    "mlp_model.add(Dense(512, activation=\"relu\", input_shape=(784,)))\n",
    "mlp_model.add(Dense(512, activation=\"relu\", input_shape=(784,)))\n",
    "mlp_model.add(Dense(10, activation=\"softmax\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.01)\n",
    "mlp_model.compile(\n",
    "    optimizer=sgd, \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "mlp_model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.96880\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = mlp_model.evaluate(X_test, y_test, verbose=0)\n",
    "acc.append(accuracy)\n",
    "print(\"Accuracy = {:.5f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN + MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.reshape(-1,28,28,1)\n",
    "X_test = X_test.reshape(-1,28,28,1)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_mlp_model = Sequential()\n",
    "cnn_mlp_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
    "cnn_mlp_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_mlp_model.add(Flatten())\n",
    "cnn_mlp_model.add(Dense(128, activation='relu'))\n",
    "cnn_mlp_model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.01)\n",
    "cnn_mlp_model.compile(\n",
    "    optimizer=sgd, \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "cnn_mlp_model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.97600\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = cnn_mlp_model.evaluate(X_test, y_test, verbose=0)\n",
    "acc.append(accuracy)\n",
    "print(\"Accuracy = {:.5f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               692352    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 693,962\n",
      "Trainable params: 693,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_mlp_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN + MLP with BatchNormalization and Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_mlp_model_2 = Sequential()\n",
    "\n",
    "\"\"\"\n",
    "Batch normalization uses weights as usual but does NOT add a bias term. \n",
    "This is because its calculations include gamma and beta variables that \n",
    "make the bias term unnecessary\n",
    "https://www.dlology.com/blog/one-simple-trick-to-train-keras-model-faster-with-batch-normalization/\n",
    "\"\"\"\n",
    "cnn_mlp_model_2.add(Conv2D(32, kernel_size=(3, 3), input_shape=(28,28,1), use_bias=False))\n",
    "cnn_mlp_model_2.add(BatchNormalization())\n",
    "\n",
    "cnn_mlp_model_2.add(Activation(\"relu\"))\n",
    "cnn_mlp_model_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\"\"\"\n",
    "Dropout is only used after the pooling layers, but this is just a rough heuristic\"\n",
    "https://machinelearningmastery.com/how-to-reduce-overfitting-with-dropout-regularization-in-keras/\n",
    "\"\"\"\n",
    "cnn_mlp_model_2.add(Dropout(0.5)) # use of 0.5 as dropout rate is arbitrary\n",
    "\n",
    "cnn_mlp_model_2.add(Flatten())\n",
    "cnn_mlp_model_2.add(Dense(128, activation='relu'))\n",
    "cnn_mlp_model_2.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.01)\n",
    "cnn_mlp_model_2.compile(\n",
    "    optimizer=sgd, \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "cnn_mlp_model_2.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.98800\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = cnn_mlp_model_2.evaluate(X_test, y_test, verbose=0)\n",
    "acc.append(accuracy)\n",
    "print(\"Accuracy = {:.5f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 26, 26, 32)        288       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               692352    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 694,058\n",
      "Trainable params: 693,994\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_mlp_model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.9688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN+MLP</th>\n",
       "      <td>0.9760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN+MLP+Batch+Dropout</th>\n",
       "      <td>0.9880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Accuracy\n",
       "MLP                      0.9688\n",
       "CNN+MLP                  0.9760\n",
       "CNN+MLP+Batch+Dropout    0.9880"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({ \"Accuracy\": acc }, index=[\"MLP\", \"CNN+MLP\", \"CNN+MLP+Batch+Dropout\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "class_virtual_env",
   "language": "python",
   "name": "class_virtual_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
